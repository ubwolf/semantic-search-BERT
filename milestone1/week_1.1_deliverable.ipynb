{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The Spanish flu, also known as the 1918 flu pandemic, was an unusually deadly influenza pandemic caused by the H1N1 influenza A virus.', 47.486176), ('As of 2018, approximately 37.9 million people are infected with HIV globally.', 44.16535), ('A pandemic is an epidemic of an infectious disease that has spread across a large region, for instance multiple continents or worldwide, affecting a substantial number of people.', 43.215614), ('The death toll of Spanish Flu is estimated to have been somewhere between 17 million and 50 million, and possibly as high as 100 million, making it one of the deadliest pandemics in human history.', 42.78693), ('The most fatal pandemic in recorded history was the Black Death (also known as The Plague), which killed an estimated 75â€“200 million people in the 14th century.', 42.419025)]\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "\n",
    "class DataLoader:\n",
    "\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "\n",
    "\n",
    "    def load_data(self):\n",
    "        with open(self.path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        return data\n",
    "\n",
    "\n",
    "    def save_data(self, data ,save_path):\n",
    "        with open(save_path, 'w') as file:\n",
    "            json.dump(data, file)\n",
    "\n",
    "\n",
    "class TransformerEncoder:\n",
    "\n",
    "    \"\"\"Elements of the TransformerEncoder class were influence by a blog post from Txus Bach\n",
    "       https://www.codegram.com/blog/finding-similar-documents-with-transformers/\"\"\"\n",
    "\n",
    "\n",
    "    def __init__(self, text_document, model_type):\n",
    "        self.data = text_document\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_type)\n",
    "        self.model = AutoModel.from_pretrained(model_type)\n",
    "\n",
    "    \n",
    "    def text_encoder(self, text):\n",
    "        text_tokens = self.tokenizer(text, return_tensors='pt')\n",
    "        embed = self.model(**text_tokens)[0].detach().squeeze()\n",
    "        return torch.mean(embed, dim=0)\n",
    "\n",
    "    \n",
    "    def search(self, query, index, k=5):\n",
    "        encoded_query = self.text_encoder(query).unsqueeze(dim=0).detach().numpy()\n",
    "        D, I = index.search(encoded_query, k)\n",
    "        return [(self.data[i], j) for i, j in zip(I[0], D[0])]\n",
    "        \n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    data = DataLoader('../data_hub/sentences.json').load_data()\n",
    "\n",
    "    encoder = TransformerEncoder(data, 'distilbert-base-uncased')\n",
    "    vectors = [encoder.text_encoder(d) for d in data]\n",
    "    index = faiss.IndexIDMap(faiss.IndexFlatIP(768))\n",
    "    index.add_with_ids(np.array([vec.numpy() for vec in vectors]), np.array(range(0, len(data))))\n",
    "\n",
    "    query = 'Spanish flu casualties?'\n",
    "    result = encoder.search(query, index, k=5)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "92b3875b50552a19f5c8b904a9bd9455a012f7f4a6644b61f5845177f2c2dbee"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('semantic_searchenv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
