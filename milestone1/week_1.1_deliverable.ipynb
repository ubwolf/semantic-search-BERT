{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('A pandemic is an epidemic of an infectious disease that has spread across a large region, for instance multiple continents or worldwide, affecting a substantial number of people.', 60.5831), ('As of 2018, approximately 37.9 million people are infected with HIV globally.', 60.17778), ('Current pandemics include COVID-19 (SARS-CoV-2) and HIV/AIDS.', 59.551132), ('Cholera is an infection of the small intestine by some strains of the bacterium Vibrio cholerae.', 58.748867), ('The Spanish flu, also known as the 1918 flu pandemic, was an unusually deadly influenza pandemic caused by the H1N1 influenza A virus.', 57.796642)]\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "\n",
    "class DataLoader:\n",
    "\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "\n",
    "\n",
    "    def load_data(self):\n",
    "        with open(self.path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        return data\n",
    "\n",
    "\n",
    "    def save_data(self, data ,save_path):\n",
    "        with open(save_path, 'w') as file:\n",
    "            json.dump(data, file)\n",
    "\n",
    "\n",
    "class TransformerEncoder:\n",
    "\n",
    "    \"\"\"Elements of the TransformerEncoder class were influence by a blog post from Txus Bach\n",
    "       https://www.codegram.com/blog/finding-similar-documents-with-transformers/\"\"\"\n",
    "\n",
    "\n",
    "    def __init__(self, text_document, model_type):\n",
    "        self.data = text_document\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_type)\n",
    "        self.model = AutoModel.from_pretrained(model_type)\n",
    "\n",
    "    \n",
    "    def text_encoder(self, text):\n",
    "        text_tokens = self.tokenizer(text, return_tensors='pt')\n",
    "        embed = self.model(**text_tokens)[0].detach().squeeze()\n",
    "        return torch.mean(embed, dim=0)\n",
    "\n",
    "    \n",
    "    def search(self, query, index, k=5):\n",
    "        encoded_query = self.text_encoder(query).unsqueeze(dim=0).detach().numpy()\n",
    "        I, D = index.search(encoded_query, k)\n",
    "        return [(self.data[i], j) for i, j in zip(D[0], I[0])]\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    data = DataLoader('../data/sentences.json').load_data()\n",
    "\n",
    "    encoder = TransformerEncoder(data, 'distilbert-base-uncased')\n",
    "    vectors = [encoder.text_encoder(d) for d in data]\n",
    "    index = faiss.IndexIDMap(faiss.IndexFlatIP(768))\n",
    "    index.add_with_ids(np.array([vec.numpy() for vec in vectors]), np.array(range(0, len(data))))\n",
    "\n",
    "    query = 'How to prevent the spread of viral infections?'\n",
    "    result = encoder.search(query, index, k=5)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "92b3875b50552a19f5c8b904a9bd9455a012f7f4a6644b61f5845177f2c2dbee"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('semantic_searchenv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
