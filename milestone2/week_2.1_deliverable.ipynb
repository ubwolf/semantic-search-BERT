{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a4d2fee90c7474db865ae830691e7ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ae9a0ae308e407aac8539768e5ec507",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(260.04678, 'Plague of Cyprian', 15), (258.3327, 'HIV/AIDS', 10), (250.29892, 'Spanish flu', 19), (247.85165, 'Swine influenza', 21), (238.0826, 'Pandemic severity index', 14)]\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import json \n",
    "import numpy as np\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "class DataLoader:\n",
    "\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "\n",
    "\n",
    "    def load_data(self):\n",
    "        with open(self.path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        return data\n",
    "\n",
    "\n",
    "    def save_data(self, data ,save_path):\n",
    "        with open(save_path, 'w') as file:\n",
    "            json.dump(data, file)\n",
    "\n",
    "\n",
    "class SentenceEncoder:\n",
    "\n",
    "    def __init__(self, text_data, model_name):\n",
    "        self.data = text_data\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.encoder = self.model.to(self.device)\n",
    "\n",
    "\n",
    "    def encode_text(self, text):\n",
    "        embeddings = self.encoder.encode(text, show_progress_bar=True)\n",
    "        return embeddings\n",
    "\n",
    "    \n",
    "    def search(self, query, index, k=5):\n",
    "        query_encoded = self.encode_text(query).reshape(1, -1)\n",
    "        D, I = index.search(query_encoded, k)\n",
    "        return D[0], I[0] \n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    data = DataLoader('../data_hub/data.json').load_data()\n",
    "\n",
    "    enc = SentenceEncoder(data, 'distilbert-base-nli-stsb-mean-tokens')\n",
    "\n",
    "    text_corpus = [i['text'] for i in data]\n",
    "    text_embeddings = enc.encode_text(text_corpus)\n",
    "\n",
    "    index = faiss.IndexFlatL2(text_embeddings.shape[1])\n",
    "    index = faiss.IndexIDMap(index)\n",
    "    index.add_with_ids(text_embeddings, np.array(range(0, text_embeddings.shape[0])))\n",
    "    # faiss.write_index(index, '../data_hub/pandemics')\n",
    "\n",
    "    q = \"How many leprosy outbreaks are known to happen?\"\n",
    "    results = enc.search(q, index)\n",
    "    results[0][::-1].sort()\n",
    "    search_results = [(i, data[j]['title'], j) for i, j in zip(results[0], results[1])]\n",
    "    print(search_results)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "92b3875b50552a19f5c8b904a9bd9455a012f7f4a6644b61f5845177f2c2dbee"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('semantic_searchenv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
